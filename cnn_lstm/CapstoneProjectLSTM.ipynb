{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZISvjEpzMPK",
        "outputId": "86153b06-ddfc-40f7-e85b-f1a71ee9c805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.24)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.24.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (1.3.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (0.28.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.5.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub->timm) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface_hub->timm) (8.3.1)\n",
            "Mounted at /content/drive\n",
            "Success! Connected to Capstone Data.\n"
          ]
        }
      ],
      "source": [
        "# 1. Install the specific library for the CNN backbone\n",
        "!pip install timm\n",
        "\n",
        "# 2. Connect to your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 3. Verify you can see your files (Change path if needed)\n",
        "import os\n",
        "# Check if your folder exists\n",
        "if os.path.exists('/content/drive/MyDrive/Seneca/Capstone/spectrograms'):\n",
        "    print(\"Success! Connected to Capstone Data.\")\n",
        "else:\n",
        "    print(\"Warning: Folder not found. Check your path in Drive.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDM_Vo612ZyC",
        "outputId": "2ab69752-aa98-40fe-db65-be883450fd50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Define paths\n",
        "zip_path = '/content/drive/MyDrive/Seneca/Capstone/spectrograms/train_spectrograms.zip'\n",
        "local_dir = '/content/train_spectrograms'\n",
        "\n",
        "print(\"Copying data to local machine (this speeds up training)...\")\n",
        "# Unzip directly to local folder\n",
        "shutil.unpack_archive(zip_path, local_dir)\n",
        "\n",
        "print(\"Done! Data is ready for the model.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY1KGNSj2KBe",
        "outputId": "9c3b04e9-978e-4940-93d6-9fbb48929569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying data to local machine (this speeds up training)...\n",
            "Done! Data is ready for the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the Validation Spectrograms\n",
        "val_zip_path = '/content/drive/MyDrive/Seneca/Capstone/spectrograms/val_spectrograms.zip'\n",
        "val_local_dir = '/content/val_spectrograms'\n",
        "\n",
        "print(\"Unzipping validation data...\")\n",
        "shutil.unpack_archive(val_zip_path, val_local_dir)\n",
        "print(\"Done! Validation data ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkNt4MWW_KWV",
        "outputId": "ddf986ff-71c0-4ab2-d10b-004e3b774935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping validation data...\n",
            "Done! Validation data ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class HMSDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        spec_id = row['spectrogram_id']\n",
        "        img_path = f\"{self.img_dir}/{spec_id}.parquet\"\n",
        "\n",
        "        try:\n",
        "            # Load data (Time is usually the index, Frequency is columns)\n",
        "            # Shape: (Time_Steps, Frequencies) e.g., (4000, 400)\n",
        "            spectrogram = pd.read_parquet(img_path).values\n",
        "        except Exception as e:\n",
        "            return torch.zeros((1, 128, 256)), torch.zeros(6)\n",
        "\n",
        "        # 1. Handle NaNs and Log Scale\n",
        "        spectrogram = np.nan_to_num(spectrogram)\n",
        "        spectrogram = np.log1p(spectrogram)\n",
        "\n",
        "        # 2. THE FIX: CENTER CROP (Time Dimension)\n",
        "        # We want a fixed time window of 256 steps.\n",
        "        # If the file is 4000 steps long, we take the middle 256.\n",
        "        # If it's too short, we pad it.\n",
        "\n",
        "        desired_time = 256\n",
        "        current_time = spectrogram.shape[0] # The variable length (e.g. 337 or 4089)\n",
        "\n",
        "        if current_time > desired_time:\n",
        "            # Crop the center\n",
        "            start = (current_time - desired_time) // 2\n",
        "            spectrogram = spectrogram[start : start + desired_time, :]\n",
        "        else:\n",
        "            # Pad with zeros if too short\n",
        "            pad_needed = desired_time - current_time\n",
        "            # Pad (Bottom, Top) -> (Time_End, Time_Start)\n",
        "            spectrogram = np.pad(spectrogram, ((0, pad_needed), (0, 0)), mode='constant')\n",
        "\n",
        "        # 3. Resize Frequency (Height) only\n",
        "        # We can safely squish frequency (e.g. 400 -> 128) without losing the \"event\"\n",
        "        # cv2.resize takes (Width, Height) -> (Frequency, Time)\n",
        "        # We want output (256, 128) -> Time=256, Freq=128\n",
        "        spectrogram = cv2.resize(spectrogram, (128, 256))\n",
        "\n",
        "        # 4. Standardize\n",
        "        mean = spectrogram.mean()\n",
        "        std = spectrogram.std() + 1e-6\n",
        "        spectrogram = (spectrogram - mean) / std\n",
        "\n",
        "        # 5. Final Shape: (Channels, Time, Freq) -> (1, 256, 128)\n",
        "        # We need to Transpose so Time is the width?\n",
        "        # Actually EfficientNet expects (C, H, W). Let's treat Time as Width.\n",
        "        spectrogram = spectrogram.T # Now (128, 256) -> (Freq, Time)\n",
        "        spectrogram = torch.tensor(spectrogram, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        # Labels\n",
        "        label_cols = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
        "        labels = row[label_cols].values.astype('float32')\n",
        "        labels = labels / (labels.sum() + 1e-6)\n",
        "\n",
        "        return spectrogram, torch.tensor(labels, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "WXJCS58fFVLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Ll2LEhUuTOqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN-LSTM Hybrid"
      ],
      "metadata": {
        "id": "9Vu2b6UMTWol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "\n",
        "class HybridLSTMSpectrogramModel(nn.Module):\n",
        "    def __init__(self, num_classes=6, hidden_size=256, num_layers=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1. The CNN Backbone (Same as Transformer version)\n",
        "        self.cnn = timm.create_model(\n",
        "            'efficientnet_b0',\n",
        "            pretrained=True,\n",
        "            in_chans=1,\n",
        "            features_only=True,\n",
        "            out_indices=[4] # Deepest block = 320 channels\n",
        "        )\n",
        "\n",
        "        cnn_out_channels = 320\n",
        "\n",
        "        # 2. The LSTM Layer\n",
        "        # Note: We don't need a projection layer here because we can just\n",
        "        # tell the LSTM that the input_size is 320.\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=cnn_out_channels,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True # Bidirectional helps it see past AND future\n",
        "        )\n",
        "\n",
        "        # 3. Classifier\n",
        "        # If bidirectional, the output size is hidden_size * 2\n",
        "        self.classifier = nn.Linear(hidden_size * 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (Batch, 1, 128, 256)\n",
        "\n",
        "        # 1. Extract Features via CNN\n",
        "        features = self.cnn(x)[0] # Shape: (Batch, 320, H, W)\n",
        "\n",
        "        # 2. Prepare for LSTM (Spatial -> Sequence)\n",
        "        # Pool the Frequency (Height), leave Time (Width)\n",
        "        features = features.mean(dim=2) # Shape: (Batch, 320, Time)\n",
        "\n",
        "        # Permute to (Batch, Time, Features) for LSTM\n",
        "        features = features.permute(0, 2, 1) # Shape: (Batch, Time, 320)\n",
        "\n",
        "        # 3. LSTM Processing\n",
        "        # output shape: (Batch, Time, hidden_size*2)\n",
        "        # _ represents hidden states we don't need right now\n",
        "        lstm_out, _ = self.lstm(features)\n",
        "\n",
        "        # 4. Global Average Pooling\n",
        "        # We take the average of all time steps to summarize the clip\n",
        "        x = lstm_out.mean(dim=1)\n",
        "\n",
        "        # 5. Classify\n",
        "        output = self.classifier(x)\n",
        "        return output"
      ],
      "metadata": {
        "id": "qvWapGmxTa_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# --- 1. Define where your files are (on the Colab machine) ---\n",
        "# You unzipped the folders here:\n",
        "TRAIN_IMG_DIR = '/content/train_spectrograms'\n",
        "VAL_IMG_DIR   = '/content/val_spectrograms'\n",
        "\n",
        "# You have the CSVs here (uploaded to Colab or Drive):\n",
        "TRAIN_CSV = '/content/drive/MyDrive/Seneca/Capstone/spectrograms/train.csv'\n",
        "VAL_CSV   = '/content/drive/MyDrive/Seneca/Capstone/spectrograms/val.csv'\n",
        "\n",
        "# --- 2. Create the Datasets ---\n",
        "# HERE is where we pass the specific CSV file!\n",
        "train_dataset = HMSDataset(csv_file=TRAIN_CSV, img_dir=TRAIN_IMG_DIR)\n",
        "val_dataset   = HMSDataset(csv_file=VAL_CSV,   img_dir=VAL_IMG_DIR)\n",
        "\n",
        "# --- 3. Create the Loaders (The Batch Makers) ---\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"Loaded {len(train_dataset)} training samples.\")\n",
        "print(f\"Loaded {len(val_dataset)} validation samples.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhTLuC8Q9zfh",
        "outputId": "29ed62c4-0ac6-4cef-c3ff-538871a29237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 85440 training samples.\n",
            "Loaded 10680 validation samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "BeInWedj_qof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training begins"
      ],
      "metadata": {
        "id": "UiTTy1Wm_vU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# 1. Define the Device (GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Training on: {device}\")\n",
        "\n",
        "# Initialize the LSTM Model\n",
        "# hidden_size=256 matches the d_model=256 of your Transformer for a fair fight\n",
        "model = HybridLSTMSpectrogramModel(num_classes=6, hidden_size=256)\n",
        "\n",
        "# Send to GPU\n",
        "model = model.to(device)\n",
        "\n",
        "# Reset the Optimizer (Crucial! The old optimizer is attached to the old model)\n",
        "# Define the Optimizer (The Teacher's Feedback)\n",
        "# AdamW is the standard \"smart\" optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
        "\n",
        "# 4. Define the Loss Function (The Grading Scale)\n",
        "# Since we are using Soft Labels (probabilities like 0.2, 0.5), we use CrossEntropyLoss\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "print(\"LSTM Model Loaded and Ready.\")"
      ],
      "metadata": {
        "id": "F1HTFP2cUIDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm # This creates a nice progress bar\n",
        "\n",
        "def train_one_epoch(dataloader, model, loss_fn, optimizer, device):\n",
        "    model.train() # Set model to \"Learning Mode\" (enables Dropout, etc.)\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # The Loop: Iterate over every batch of data\n",
        "    # tqdm wraps the loader to show a progress bar\n",
        "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
        "\n",
        "    for inputs, targets in progress_bar:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # A. Reset Gradients (Clear previous mistakes)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # B. Forward Pass (The Model guesses)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # C. Calculate Loss (Compare guess vs truth)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        # D. Backward Pass (Calculate adjustments)\n",
        "        loss.backward()\n",
        "\n",
        "        # E. Optimize (Update weights)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Keep track of the score\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Update progress bar\n",
        "        progress_bar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "    return running_loss / len(dataloader)\n",
        "\n",
        "def validate_one_epoch(dataloader, model, loss_fn, device):\n",
        "    model.eval() # Set model to \"Test Mode\" (freezes layers)\n",
        "    running_loss = 0.0\n",
        "\n",
        "    with torch.no_grad(): # Don't calculate gradients (saves memory)\n",
        "        for inputs, targets in tqdm(dataloader, desc=\"Validating\", leave=False):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "    return running_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "oYvXvoayAtSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# --- Configuration ---\n",
        "NUM_EPOCHS = 10             # How many times to study the whole dataset\n",
        "best_val_loss = float('inf') # Track the best score to save the best model\n",
        "history = {'train_loss': [], 'val_loss': []} # To plot a graph later\n",
        "\n",
        "print(f\"Starting training for {NUM_EPOCHS} epochs on {device}...\")\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # --- 1. Train (The Model Studies) ---\n",
        "    # Note: We use the function definitions I gave you earlier\n",
        "    train_loss = train_one_epoch(train_loader, model, loss_fn, optimizer, device)\n",
        "\n",
        "    # --- 2. Validate (The Model Takes a Quiz) ---\n",
        "    val_loss = validate_one_epoch(val_loader, model, loss_fn, device)\n",
        "\n",
        "    # --- 3. Record History ---\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "\n",
        "    # --- 4. Print Progress ---\n",
        "    # We print a clean line so you can see if it's improving\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    # --- 5. Save the \"Best\" Version ---\n",
        "    # If the model scored better on the quiz than ever before, save it!\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"best_transformer_model.pth\")\n",
        "        print(f\"  --> New best model saved! (Loss: {val_loss:.4f})\")\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print(f\"\\nTraining Complete in {total_time/60:.2f} minutes!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9sNxV7KBqvZ",
        "outputId": "3ab20103-219f-4ebb-dca0-7d7f48de13a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 10 epochs on cuda...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 1.1289 | Val Loss: 1.3567\n",
            "  --> New best model saved! (Loss: 1.3567)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   6%|â–Œ         | 161/2670 [02:47<41:11,  1.02it/s, loss=0.971]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XKFixoTYBoY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4_fRDLD0A4Rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already created 'train_loader' and 'val_loader' using the HMSDataset class\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "print(\"Starting Training...\")\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # 1. Train\n",
        "    train_loss = train_one_epoch(train_loader, model, loss_fn, optimizer, device)\n",
        "\n",
        "    # 2. Validate\n",
        "    val_loss = validate_one_epoch(val_loader, model, loss_fn, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    # 3. Save the Best Model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"best_transformer_model.pth\")\n",
        "        print(\"  >>> New Best Model Saved!\")\n",
        "\n",
        "print(\"Training Complete!\")"
      ],
      "metadata": {
        "id": "cT3MTNfMA4wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k_OpTl86B-Iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xXmuc9Q1Rsrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mLacT26ET7CT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ignore everything below this\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ZDY9VSEwRuDM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tf-JC7OAB957"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- IMPORT YOUR CUSTOM CODE ---\n",
        "# These imports assume you created the files I gave you earlier\n",
        "from load_data import HMSDataset\n",
        "# Note: You need to create the model.py file with the 'HybridModel' class\n",
        "# I gave you in the previous step for this import to work.\n",
        "from app.model import HybridModel\n",
        "\n",
        "# --- CONFIGURATION (The Control Panel) ---\n",
        "DEBUG_MODE = True  # <--- SET THIS TO TRUE FOR MAC/WINDOWS TESTING\n",
        "                   # <--- SET THIS TO FALSE FOR ACTUAL GPU TRAINING\n",
        "\n",
        "BATCH_SIZE = 8     # Small batch size is safer for laptops\n",
        "LEARNING_RATE = 1e-4\n",
        "NUM_EPOCHS = 1 if DEBUG_MODE else 10\n",
        "DATA_PATH = \"./data\"\n",
        "CSV_FILE = os.path.join(DATA_PATH, \"train.csv\")\n",
        "SPECTROGRAM_PATH = os.path.join(DATA_PATH, \"train_spectrograms\")\n",
        "SAVE_PATH = \"./app/models/hms_model.pt\"\n",
        "\n",
        "def train():\n",
        "    # 1. Hardware Check\n",
        "    # This automatically picks GPU if available, otherwise CPU\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"--- Running on: {device} ---\")\n",
        "    if DEBUG_MODE:\n",
        "        print(\"!! DEBUG MODE ACTIVE: Running on tiny dataset subset !!\")\n",
        "\n",
        "    # 2. Load Data\n",
        "    print(\"Initializing Dataset...\")\n",
        "    full_dataset = HMSDataset(CSV_FILE, SPECTROGRAM_PATH)\n",
        "\n",
        "    if DEBUG_MODE:\n",
        "        # If debugging, only grab the first 16 items (2 batches)\n",
        "        # This makes the \"epoch\" finish instantly\n",
        "        full_dataset.data = full_dataset.data.iloc[:16]\n",
        "\n",
        "    dataloader = DataLoader(full_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    print(f\"Data Loaded: {len(full_dataset)} samples\")\n",
        "\n",
        "    # 3. Initialize Model\n",
        "    print(\"Initializing Model...\")\n",
        "    model = HybridModel().to(device)\n",
        "\n",
        "    # 4. Define Loss & Optimizer\n",
        "    # KLDivLoss is standard for when your targets are probabilities (vote percentages)\n",
        "    criterion = nn.KLDivLoss(reduction='batchmean')\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    # 5. The Training Loop\n",
        "    print(\"\\nStarting Training...\")\n",
        "    model.train() # Set model to training mode (enables Dropout, etc.)\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        start_time = time.time()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i, (inputs, targets) in enumerate(dataloader):\n",
        "            # Move data to the same device as the model (CPU or GPU)\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # Zero the gradients (reset from last step)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass (Guess)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Use LogSoftmax for KLDivLoss stability\n",
        "            outputs = torch.log_softmax(outputs, dim=1)\n",
        "\n",
        "            # Calculate Loss (Error)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # Backward pass (Learn)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Print progress every 10 batches (or every batch in debug)\n",
        "            if DEBUG_MODE or (i + 1) % 10 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "        # End of Epoch Stats\n",
        "        epoch_loss = running_loss / len(dataloader)\n",
        "        print(f\"Epoch [{epoch+1}] Complete. Avg Loss: {epoch_loss:.4f}. Time: {time.time() - start_time:.2f}s\")\n",
        "\n",
        "    # 6. Save the Model\n",
        "    print(\"\\nSaving Model...\")\n",
        "    # Create the folder if it doesn't exist\n",
        "    os.makedirs(os.path.dirname(SAVE_PATH), exist_ok=True)\n",
        "    torch.save(model.state_dict(), SAVE_PATH)\n",
        "    print(f\"Model saved to {SAVE_PATH}\")\n",
        "    print(\"Done!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train()"
      ],
      "metadata": {
        "id": "o9XWv0ZA_p1M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}