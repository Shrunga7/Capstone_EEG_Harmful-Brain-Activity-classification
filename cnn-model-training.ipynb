{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Data Loading and Preparation","metadata":{}},{"cell_type":"code","source":"import os, random\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import IterableDataset, DataLoader, get_worker_info\n\nDATA_ROOT = \"/kaggle/input/hms-harmful-brain-activity-classification\" # dataset folder\ntrain = pd.read_csv(f\"{DATA_ROOT}/train.csv\") # reads into Dataframe\nSPEC_DIR = f\"{DATA_ROOT}/train_spectrograms\" # folder containing spectrogram parquet files.\ndef soft_label(row):\n    v = np.array([\n        row[\"seizure_vote\"], row[\"lpd_vote\"], row[\"gpd_vote\"],\n        row[\"lrda_vote\"], row[\"grda_vote\"], row[\"other_vote\"],\n    ], dtype=np.float32)\n    v = v / (v.sum() + 1e-6) # normalizes so values sum to 1\n    return v\n\n# Keep only columns needed for training (saving RAM)\n# “Load spectrogram <id>”\n# “Crop around <offset>”\n# “Use label distribution <soft>”\nuse_cols = [\"spectrogram_id\", \"spectrogram_label_offset_seconds\",\n            \"seizure_vote\",\"lpd_vote\",\"gpd_vote\",\"lrda_vote\",\"grda_vote\",\"other_vote\"] # votes used to build label\ndf = train[use_cols].copy()\ndf[\"soft\"] = df.apply(soft_label, axis=1) # adds a new column soft which contains the 6D probability vector for each row\n\ndisplay(\"Required Training columns:\", df)\n\n# Shape of the first paraquet file\ntmp = pd.read_parquet(f\"{SPEC_DIR}/{df.iloc[0].spectrogram_id}.parquet\")\nprint(tmp.shape)\nprint(tmp.columns[:15])\n\n# For reference\nCLASSES = [\"seizure\", \"lpd\", \"gpd\", \"lrda\", \"grda\", \"other\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T17:08:07.945970Z","iopub.execute_input":"2026-01-29T17:08:07.946317Z","iopub.status.idle":"2026-01-29T17:08:10.511474Z","shell.execute_reply.started":"2026-01-29T17:08:07.946290Z","shell.execute_reply":"2026-01-29T17:08:10.510622Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"'Required Training columns:'"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"        spectrogram_id  spectrogram_label_offset_seconds  seizure_vote  \\\n0               353733                               0.0             3   \n1               353733                               6.0             3   \n2               353733                               8.0             3   \n3               353733                              18.0             3   \n4               353733                              24.0             3   \n...                ...                               ...           ...   \n106795      2147388374                              12.0             0   \n106796      2147388374                              14.0             0   \n106797      2147388374                              16.0             0   \n106798      2147388374                              18.0             0   \n106799      2147388374                              20.0             0   \n\n        lpd_vote  gpd_vote  lrda_vote  grda_vote  other_vote  \\\n0              0         0          0          0           0   \n1              0         0          0          0           0   \n2              0         0          0          0           0   \n3              0         0          0          0           0   \n4              0         0          0          0           0   \n...          ...       ...        ...        ...         ...   \n106795         0         0          3          0           0   \n106796         0         0          3          0           0   \n106797         0         0          3          0           0   \n106798         0         0          3          0           0   \n106799         0         0          3          0           0   \n\n                                        soft  \n0       [0.9999997, 0.0, 0.0, 0.0, 0.0, 0.0]  \n1       [0.9999997, 0.0, 0.0, 0.0, 0.0, 0.0]  \n2       [0.9999997, 0.0, 0.0, 0.0, 0.0, 0.0]  \n3       [0.9999997, 0.0, 0.0, 0.0, 0.0, 0.0]  \n4       [0.9999997, 0.0, 0.0, 0.0, 0.0, 0.0]  \n...                                      ...  \n106795  [0.0, 0.0, 0.0, 0.9999997, 0.0, 0.0]  \n106796  [0.0, 0.0, 0.0, 0.9999997, 0.0, 0.0]  \n106797  [0.0, 0.0, 0.0, 0.9999997, 0.0, 0.0]  \n106798  [0.0, 0.0, 0.0, 0.9999997, 0.0, 0.0]  \n106799  [0.0, 0.0, 0.0, 0.9999997, 0.0, 0.0]  \n\n[106800 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>spectrogram_id</th>\n      <th>spectrogram_label_offset_seconds</th>\n      <th>seizure_vote</th>\n      <th>lpd_vote</th>\n      <th>gpd_vote</th>\n      <th>lrda_vote</th>\n      <th>grda_vote</th>\n      <th>other_vote</th>\n      <th>soft</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>353733</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0.9999997, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>353733</td>\n      <td>6.0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0.9999997, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>353733</td>\n      <td>8.0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0.9999997, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>353733</td>\n      <td>18.0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0.9999997, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>353733</td>\n      <td>24.0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0.9999997, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>106795</th>\n      <td>2147388374</td>\n      <td>12.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0.0, 0.0, 0.0, 0.9999997, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>106796</th>\n      <td>2147388374</td>\n      <td>14.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0.0, 0.0, 0.0, 0.9999997, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>106797</th>\n      <td>2147388374</td>\n      <td>16.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0.0, 0.0, 0.0, 0.9999997, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>106798</th>\n      <td>2147388374</td>\n      <td>18.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0.0, 0.0, 0.0, 0.9999997, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>106799</th>\n      <td>2147388374</td>\n      <td>20.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0.0, 0.0, 0.0, 0.9999997, 0.0, 0.0]</td>\n    </tr>\n  </tbody>\n</table>\n<p>106800 rows × 9 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"(320, 401)\nIndex(['time', 'LL_0.59', 'LL_0.78', 'LL_0.98', 'LL_1.17', 'LL_1.37',\n       'LL_1.56', 'LL_1.76', 'LL_1.95', 'LL_2.15', 'LL_2.34', 'LL_2.54',\n       'LL_2.73', 'LL_2.93', 'LL_3.13'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ---- Spectrogram window loader from parquet  to tensor window----\n#loads one spectrogram file and extracts a small time window.\ndef load_spec_window_parquet(spec_id: int, offset_s: float, window_seconds: float = 10.0):\n    path = os.path.join(SPEC_DIR, f\"{spec_id}.parquet\")\n    spec_df = pd.read_parquet(path)\n\n    # Separate time and frequency data\n    time = spec_df[\"time\"].to_numpy()\n    freq_mat = spec_df.drop(columns=[\"time\"]).to_numpy(dtype=np.float32)\n    # freq_mat shape: (time_steps, freq_bins)\n\n    # Find center index closest to offset_s\n    center_idx = np.argmin(np.abs(time - offset_s))\n\n    # Estimate time resolution\n    dt = np.median(np.diff(time))  # seconds per row\n    half_window = int(round((window_seconds / 2) / dt))\n\n    start = max(0, center_idx - half_window)\n    end   = min(len(time), center_idx + half_window)\n\n    window = freq_mat[start:end, :]  # (time, freq)\n\n    # Pad if near edges\n    if window.shape[0] < 2 * half_window:\n        pad = 2 * half_window - window.shape[0]\n        window = np.pad(window, ((0, pad), (0, 0)), mode=\"constant\")\n\n    # Log + normalize\n    window = np.log1p(np.maximum(window, 0))\n    window = (window - window.mean()) / (window.std() + 1e-6)\n\n    # CNN format: (C, H, W) = (1, freq, time)\n    window = window.T  # (freq, time)\n    return window[None, :, :]  # (1, freq, time)\n\n\n\n#-------STREAMING DATASET CLASS------------#\nclass HMSParquetStream(IterableDataset):\n    def __init__(self, df, shuffle=True, infinite=True, window_seconds=10):\n        self.df = df.reset_index(drop=True)\n        self.shuffle = shuffle\n        self.infinite = infinite #if True, it loops forever (continuous feed)\n        self.window_seconds = window_seconds\n        \n    #--Iterator: main streaming loop---#\n    #GPU → does math (CNN forward + backward)\n    #CPU workers → read files, crop spectrograms, normalize, convert to tensors\n    \n    def __iter__(self):\n        worker = get_worker_info() #Background CPU processes\n        start, step = (0, 1) if worker is None else (worker.id, worker.num_workers)\n        \n        idxs = list(range(len(self.df))) #Create list of indices\n        #Infinite loop (continuous feed)\n        while True: \n            if self.shuffle:\n                random.shuffle(idxs)\n            #Worker-sharded iteration\n            for k in range(start, len(idxs), step):\n                row = self.df.iloc[idxs[k]] #Load one training row from the dataset\n                \n                #Load spectrogram window -> opens, crops, returns shape (1, F, window_seconds)\n                x = load_spec_window_parquet(\n                    int(row.spectrogram_id),\n                    float(row.spectrogram_label_offset_seconds),\n                    seconds=self.window_seconds\n                )\n                y = row.soft #Get soft labels\n                \n                #Yield tensors to DataLoader -> Each yielded item is (input_tensor, label_tensor).\n                yield torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32) \n            \n            #If infinite=False, it runs only one “epoch” and stops.\n            if not self.infinite:\n                break\n\n# CREATE STREAM + DATALOADER\n# stream: your continuous generator of samples\n# DataLoader:\n# batch_size=32: groups 32 samples into a batch\n# num_workers=2: runs 2 parallel worker processes to load data\n# pin_memory=True: speeds CPU→GPU transfer\n# persistent_workers=True: keeps workers alive between iterations (faster)\n\nstream = HMSParquetStream(df, shuffle=True, infinite=True, window_seconds=10)\nloader = DataLoader(stream, batch_size=32, num_workers=2, pin_memory=True, persistent_workers=True)\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-29T17:15:44.656829Z","iopub.execute_input":"2026-01-29T17:15:44.657699Z","iopub.status.idle":"2026-01-29T17:15:47.238665Z","shell.execute_reply.started":"2026-01-29T17:15:44.657661Z","shell.execute_reply":"2026-01-29T17:15:47.237306Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### CNN Training Example  \nThe DataLoader continuously pulls spectrogram windows from streaming dataset (which loads+extracts them from parquet), batches them into x, and the loop repeatedly runs forward → loss → backward → optimizer step to train the CNN.\n\n**Spectrogram → CNN → window-level probabilities**\n\n**FETCHING THE EXTRACTED SPECTROGRAM WINDOWS**\n* loader is a DataLoader built from HMSParquetStream(IterableDataset).\n* When the loop asks for the next batch, the DataLoader tells its workers: “Give me the next samples.”\n* Each worker runs the dataset’s __iter__() method, which does this for each sample:\n* picks one row from df  \n* calls load_spec_window_parquet(spec_id, offset_s, window_seconds)\n* which reads the parquet file, finds the correct time row closest to offset_s\n* slices a window of rows (time) and all columns (freq)\n* normalizes it\n* returns (1, freq, time) tensor\n* The DataLoader takes 32 of these samples and stacks them into a batch:\n* x becomes shape: (B, 1, freq, time), where B=32\n* y becomes shape: (B, 6) soft labels\n* So the “fetching” is not done by the CNN directly — it’s done by:\n* ✅ DataLoader → ✅ IterableDataset.__iter__() → ✅ load_spec_window_parquet()","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = model.to(device) #Moves your CNN weights to GPU/CPU\nopt = torch.optim.AdamW(model.parameters(), lr=1e-3) #Creates an optimizer (AdamW) that will update the model weights to reduce loss.\n\nfor step, (x, y) in enumerate(loader): #Training starts\n    x = x.to(device, non_blocking=True) #Moves the batch to GPU.  \n    y = y.to(device, non_blocking=True) # non_blocking=True-> CPU starts the transfer and immediately moves on to the next task\n    \n    logits = model(x)  # (B, 6) #Feeds the spectrogram batch into CNN. logits gives raw score per class\n    loss = torch.nn.functional.kl_div(\n        torch.log_softmax(logits, dim=1), #converts logits to log probabilities and computes KL divergence loss bwt model pred distr. & soft lable distr.\n        y,\n        reduction=\"batchmean\"\n    )\n\n    loss.backward() #Computes gradients (how each weight should change to reduce loss).\n    opt.step() # Updates model weights using those gradients.\n    opt.zero_grad() # Clears gradients so they don’t accumulate into the next step.\n\n    #LOGGING + STOPPING\n    if step % 100 == 0:\n        print(step, float(loss)) #Prints loss every 100 batches.\n\n    if step == 5000:   # stops after 5000 batches since it's streaming infinitely\n        break","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### For monitoring the training outputs:","metadata":{}},{"cell_type":"code","source":"#Loss Curve\nlosses.append(loss.item())\n\n#Accuracy (window-level)\npred = logits.argmax(dim=1)\ntrue = y.argmax(dim=1)\nacc = (pred == true).float().mean()\n\n#Save Checkpoints\nif step % 1000 == 0:\n    torch.save(model.state_dict(), f\"model_step_{step}.pth\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### After training Save & Reload the model\n\n","metadata":{}},{"cell_type":"code","source":"# Saves only the learned weights\nMODEL_PATH = \"cnn_hms_trained.pth\"\ntorch.save(model.state_dict(), MODEL_PATH)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Reload the model\nmodel = MyCNN()        # same architecture as training\nmodel.load_state_dict(torch.load(MODEL_PATH, map_location=device))\nmodel = model.to(device)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Freeze + Inference\noutput is final predicted class (per window)","metadata":{}},{"cell_type":"code","source":"model.eval() #freezes the current batch and uses the running mean/variance learned during training\nwith torch.no_grad(): # The \"Memory Saver\". Freezes the weights\n    probs = model(x) # probs here are logits (raw scores\nprobs = torch.softmax(model(x), dim=1) # final class probabilities\npreds = probs.argmax(dim=1) # final predicted class (per window) [ P(seizure), P(lpd), P(gpd), P(lrda), P(grda), P(other) ]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Scenario 2 (CNN + LSTM/Transformer) is only for aggregating across windows/patients.\nBelow is the **freeze + Inference step**\nCompletely disables gradient computation for parameters  \nPrevents any weight updates  \nMostly used for:  \ntransfer learning  \nfeature extractors  \npartial freezing  ","metadata":{}},{"cell_type":"code","source":"model.eval()\nfor p in model.parameters():\n    p.requires_grad = False","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}